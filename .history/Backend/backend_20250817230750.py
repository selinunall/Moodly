from flask import Flask, request, jsonify
import google.generativeai as genai
import os
from dotenv import load_dotenv
import google.generativeai as genai
import json
import redis

load_dotenv()  # .env dosyasÄ±nÄ± yÃ¼kler
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

app = Flask(__name__)

# Model seÃ§
model = genai.GenerativeModel("gemini-1.5-flash")

redis_client = redis.Redis(host="localhost", port=6379, db=0, decode_responses=True)

# RAM'de kullanÄ±cÄ± oturumlarÄ±nÄ± saklamak iÃ§in dictionary
user_sessions = {}

prompt="KullanÄ±cÄ±ya psikolojik destek saÄŸlayan bir asistan olarak davranacaksÄ±n. KullanÄ±cÄ±ya nazik ve destekleyici ÅŸekilde cevap ver. DuygularÄ±nÄ±, diyaloglardan analiz et. KullanÄ±cÄ±nÄ±n durumuna gÃ¶re tavsiyelerde bulun. KullanÄ±cÄ±nÄ±n ruh halini iyileÅŸtirmeye Ã§alÄ±ÅŸan bir arkadaÅŸ gibi davran." 

# Redis key fonksiyonu
def redis_key(user_id: str) -> str:
    return f"chat:{user_id}:history"

# KullanÄ±cÄ±nÄ±n sohbet geÃ§miÅŸini getir
def get_user_history(user_id: str):
    history_json = redis_client.get(redis_key(user_id))
    if history_json:
        return json.loads(history_json)
    else:
        # Yeni kullanÄ±cÄ± â†’ baÅŸlangÄ±Ã§ prompt ve model karÅŸÄ±lama mesajÄ±
        return [
            {"role": "user", "parts": [{"text": prompt}]},
            {"role": "model", "parts": [{"text": "Merhaba, size nasÄ±l yardÄ±mcÄ± olabilirim?"}]}
        ]

# KullanÄ±cÄ±nÄ±n geÃ§miÅŸini kaydet
def save_user_history(user_id: str, history):
    redis_client.set(redis_key(user_id), json.dumps(history))


@app.route("/chat", methods=["POST"])
def chat():
    try:
        data = request.get_json()
        user_id = data.get("user_id")
        user_message = data.get("message", "").strip()

        if not user_id or not user_message:
            return jsonify({"error": "user_id ve message zorunlu"}), 400

        # 1) GeÃ§miÅŸi al
        history = get_user_history(user_id)

        # 2) Yeni mesajÄ± geÃ§miÅŸe ekle
        history.append({"role": "user", "parts": [{"text": user_message}]})

        # 3) Modelden yanÄ±t al
        chat_session = model.start_chat(history=history)
        response = chat_session.send_message({"role":"user","parts":[{"text": user_message}]})
        ai_message = response.text

        # 4) AI mesajÄ±nÄ± da geÃ§miÅŸe ekle
        history.append({"role": "model", "parts": [{"text": ai_message}]})

        # 5) GÃ¼ncellenmiÅŸ geÃ§miÅŸi Redisâ€™e kaydet
        save_user_history(user_id, history)

        return jsonify({"reply": ai_message})

    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/", methods=["GET"])
def home():
    return "Backend Ã§alÄ±ÅŸÄ±yor ğŸš€"

if __name__ == "__main__":
    app.run(debug=True, port=5000)
